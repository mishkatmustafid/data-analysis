{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f755a768-1c18-4636-818b-ea52d1a39274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "from folium.plugins import HeatMap\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import skew, kurtosis\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae326c8-4a78-4e01-ac9a-75a1db4b594b",
   "metadata": {},
   "source": [
    "#### Filtering the dataset by Borough Name and storing them as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b3644d-5fc1-4a00-9130-eeefb2b98550",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data = pd.read_excel(r'datasets/LFB_2019-22.xlsx')\n",
    "dataset = read_data[read_data.IncGeo_BoroughName.str.contains('HAMMERSMITH AND FULHAM')]\n",
    "dataset.to_csv('datasets/dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fbd08a-e905-4f38-9e4f-759b41b3f105",
   "metadata": {},
   "source": [
    "#### Removing Zero-Variance Columns\n",
    "#### Those columns are IncGeo_BoroughCode, IncGeo_BoroughName, ProperCase, FRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d0fc9-a7aa-4f3e-b081-0412948f5089",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'datasets/dataset.csv')\n",
    "for column in df.columns:\n",
    "    if len(df[column].unique()) == 1:\n",
    "        df = df.drop(column, axis=1)\n",
    "        print(column)\n",
    "df.to_csv('datasets/filter_data.csv', index_label='Index')\n",
    "df = pd.read_csv('datasets/filter_data.csv', index_col='Index', parse_dates=[\"DateOfCall\"], dtype={\"CalYear\": int, \"HourOfCall\": int})\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5445828-8f4a-4cfc-a18a-aba232303eea",
   "metadata": {},
   "source": [
    "#### Code for script (re-evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1afbb5-4a5f-424e-ab60-3b9672545749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sample data\n",
    "data = pd.read_csv(\"datasets/dataset.csv\")\n",
    "\n",
    "# select relevant columns\n",
    "features = [\"TimeOfCall\", \"PropertyCategory\", \"PropertyType\", \"Postcode_district\"]\n",
    "target = \"IncidentGroup\"\n",
    "\n",
    "# convert categorical columns to numeric using one-hot encoding\n",
    "data = pd.get_dummies(data[features + [target]])\n",
    "target = \"IncidentGroup_False Alarm\"\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data.drop(target, axis=1), data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# train a decision tree classifier\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test set and calculate accuracy\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                           feature_names=X_train.columns,  \n",
    "                           class_names=[\"False Alarm\", \"Other\"],  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)  \n",
    "graph = graphviz.Source(dot_data)  \n",
    "graph.render(\"false_alarm_tree\")  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8bb46eb-4048-447a-83b5-c0418f6362f6",
   "metadata": {},
   "source": [
    "### Percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ba9df8-7c09-41a9-b4ed-d2413034a856",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the percentage of missing values in each column\n",
    "missing_values = df.isnull().mean() * 100\n",
    "\n",
    "# Filter out columns with 0% missing values\n",
    "missing_values = missing_values[missing_values > 0].sort_values(ascending=True)\n",
    "\n",
    "# Plot the percentage of missing values in each column in a bar graph\n",
    "fig, ax = plt.subplots(figsize=(8, 10))\n",
    "missing_values.plot(kind='barh', ax=ax, color='c')\n",
    "ax.set_xlabel('Percentage of missing values')\n",
    "ax.set_title('Percentage of missing values by column')\n",
    "# ax.set_xticklabels(missing_values.index, rotation=45, ha='right')\n",
    "# ax.set_xticks(range(len(missing_values.index)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3565dd-c70d-434f-8c20-244835c8baee",
   "metadata": {},
   "source": [
    "### Graph of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1260a374-7fca-4eb3-9d2a-480f9c91aa32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "msno.matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc91215-5e6b-4542-af1c-65c77b89b79e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4044a2c9-d94b-46b5-9cd6-8a9215f73453",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_false_alarms = df[df['IncidentGroup'] == 'False Alarm']\n",
    "\n",
    "# Drop rows with null values in the Latitude and Longitude columns\n",
    "df_heatmap = df_false_alarms.dropna(subset=['Latitude', 'Longitude'])\n",
    "\n",
    "# Create a map object centered on the mean of the latitude and longitude columns\n",
    "m = folium.Map(location=[51.498611, -0.210884], zoom_start=13.5)\n",
    "\n",
    "# Create a list of coordinates from the Latitude and Longitude columns\n",
    "coordinates = df_heatmap[['Latitude', 'Longitude']].values.tolist()\n",
    "\n",
    "# Create a heatmap layer\n",
    "heatmap = HeatMap(data=coordinates)\n",
    "\n",
    "# Add the heatmap layer to the map\n",
    "heatmap.add_to(m)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9869e55a-874d-405f-8449-fcd97f131198",
   "metadata": {},
   "source": [
    "### Skewness and Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82a5f49-65a7-4ecb-b39a-70265580503c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.select_dtypes(include='number'):\n",
    "    # if df[column].isnull().sum() == 0:\n",
    "    print(f\"Column: {column}\")\n",
    "    print(f\"Skewness: {skew(df[column])}\")\n",
    "    print(f\"Kurtosis: {kurtosis(df[column])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f91ca98-a915-43bf-a6b1-164a2d2438bf",
   "metadata": {},
   "source": [
    "### Density plot of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a95a7-f972-4b97-926b-86783a785a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = df.drop('StopCodeDescription', axis=1)\n",
    "row_missing = df_1.isna().mean(axis=1) * 100\n",
    "\n",
    "# Create a density plot of the percentage of missing values\n",
    "sns.kdeplot(row_missing)\n",
    "plt.xlabel('Percentage of missing values')\n",
    "plt.title('Density plot of missing values per row')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24223d49-54db-4519-9e60-bad9cea36cf3",
   "metadata": {},
   "source": [
    "### Count plot for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e9d42-668c-4c1a-a0da-b4268f7e510b",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_null_counts = df.iloc[:, ::-1].shape[0] - df.iloc[:, ::-1].isnull().sum()\n",
    "\n",
    "# create bar plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.barh(non_null_counts.index, non_null_counts)\n",
    "\n",
    "# set x-axis and y-axis labels\n",
    "plt.xlabel('Number of Non-Null Values')\n",
    "plt.ylabel('Columns')\n",
    "\n",
    "# display plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7349e870-eb5e-45c4-8f66-c88d02956891",
   "metadata": {},
   "source": [
    "### Nominal cost per pump hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889c10f1-d52a-42cc-bec4-5dd80fcf53ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df['Notional Cost (Â£)'] / df['PumpHoursRoundUp']\n",
    "\n",
    "# Create a line plot for the new column\n",
    "plt.plot(x)\n",
    "avg_cost_per_hour = x.mean()\n",
    "plt.axhline(y=avg_cost_per_hour, color='r', linestyle='--')\n",
    "\n",
    "# Set the labels for the plot\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Cost per Hour')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3be36dd-55ab-4bf3-8f34-212004a97883",
   "metadata": {},
   "source": [
    "### Elbow curve and Silhouette score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f9507-e5ac-4403-a8bf-eab7df9eeef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[df['IncidentGroup'] != 'False Alarm']\n",
    "\n",
    "# Preprocess the data\n",
    "le = LabelEncoder()\n",
    "df['StopCodeDescription'] = le.fit_transform(df['StopCodeDescription'])\n",
    "df['DatetimeOfCall'] = pd.to_datetime(df['DatetimeOfCall'])\n",
    "df['DatetimeOfCall'] = df['DatetimeOfCall'].astype(int)\n",
    "\n",
    "# Select the relevant columns\n",
    "X = df[['DatetimeOfCall', 'StopCodeDescription']]\n",
    "\n",
    "# Create an empty list to store the inertia values for different k\n",
    "inertia_values = []\n",
    "\n",
    "# Use a for loop to fit KMeans with different values of k\n",
    "for k in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "\n",
    "# Plot the elbow curve\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(1, 11), inertia_values)\n",
    "plt.title('Elbow Curve')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.show()\n",
    "\n",
    "silhouette_scores = []\n",
    "\n",
    "# Use a for loop to fit KMeans with different values of k and compute the silhouette score\n",
    "for k in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    labels = kmeans.labels_\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "# Plot the silhouette scores\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(range(2, 11), silhouette_scores)\n",
    "plt.title('Silhouette Score')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
